Файл Clusterisation_types_kmeans10:
1.Чтение данных в DataFrame и их конкатенация для дальнейшего проведения кластеризации.
2.Исследование данных (пропуски, типы данных).
3.Удаление колонок 'main_photo', 'is_markup', 'target', 'stratify_column'.
4.Удаление колонок "category_l2", "category_l4", т.к. в них много пропущенных значений.
5.Очищаем текст с помощью функции clean_text.
6.Лемматизация с помощью функции lemmatize_text.
Эксперимент с алгоритмом кластеризации kmeans, количество кластеров - 10.
1.Создание объекта tf.data.Dataset.
2.Векторизация с использованием TensorFlow.
3.Сохранение разреженной матрицы.
4.Собственно кластеризация.
5.Сохранение модели в файл 'kmeans.pkl'.
6.Сохранение результатов кластеризации в отдельную колонку.
Эксперимент с алгоритмом классификации k ближайших соседей.
1.Обучение модели.
2.Сохранение модели в файл 'knn_model_full.pkl'.
3.Сохранение scaler в файл 'scaler.pkl.
4.Сохранение векторизатора в файл 'text_vectorization_layer.keras'.
Clusterisation_types_kmeans100 - векторизация word2vec:
1.Чтение данных в DataFrame и их конкатенация для дальнейшего проведения кластеризации.
2.Исследование данных (пропуски, типы данных).
3.Удаление колонок 'main_photo', 'is_markup', 'target', 'stratify_column'.
4.Удаление колонок "category_l2", "category_l4", т.к. в них много пропущенных значений.
5.Очищаем текст с помощью функции clean_text.
6.Лемматизация с помощью функции lemmatize_text.
Эксперимент с алгоритмом кластеризации kmeans, количество кластеров - 30.
1.Создание объекта tf.data.Dataset.
2.Векторизация с использованием TensorFlow.
3.Сохранение разреженной матрицы.
4.Собственно кластеризация.
5.Сохранение модели в файл 'kmeans.pkl'.
6.Сохранение результатов кластеризации в отдельную колонку.
Эксперимент с алгоритмом классификации k ближайших соседей.
1.Обучение модели.
2.Сохранение модели в файл 'knn_model_full.pkl'.
3.Сохранение scaler в файл 'scaler.pkl.
4.Сохранение векторизатора в файл 'text_vectorization_layer.keras'.
Файл Clusterisation_types_kmeans100 - векторизация word2vec:
1.Чтение данных в DataFrame и их конкатенация для дальнейшего проведения кластеризации.
2.Исследование данных (пропуски, типы данных).
3.Удаление колонок 'main_photo', 'is_markup', 'target', 'stratify_column'.
4.Удаление колонок "category_l2", "category_l4", т.к. в них много пропущенных значений.
5.Очищаем текст с помощью функции clean_text.
6.Лемматизация с помощью функции lemmatize_text.
Эксперимент с алгоритмом кластеризации kmeans, количество кластеров - 10.
1.Векторизация с использованием word2vec.
2.Собственно кластеризация.
3.Сохранение модели в файл 'kmeans_100_w2v.pkl'.
4.Сохранение результатов кластеризации в отдельную колонку.
Эксперимент с алгоритмом классификации k ближайших соседей.
1.Обучение модели.
2.Сохранение модели в файл 'knn_model_100.pkl'.
3.Сохранение scaler в файл 'scaler.pkl.
4.Расчет метрики roc-auc.
Файл Clusterisation_types_kmeans100 - векторизация tfidf:
1.Чтение данных в DataFrame и их конкатенация для дальнейшего проведения кластеризации.
2.Исследование данных (пропуски, типы данных).
3.Удаление колонок 'main_photo', 'is_markup', 'target', 'stratify_column'.
4.Удаление колонок "category_l2", "category_l4", т.к. в них много пропущенных значений.
5.Очищаем текст с помощью функции clean_text.
6.Лемматизация с помощью функции lemmatize_text.
Эксперимент с алгоритмом кластеризации kmeans, количество кластеров - 100.
1.Векторизация с использованием tf-idf.
2.Собственно кластеризация.
3.Сохранение модели в файл 'kmeans_tfidf.pkl'.
4.Сохранение результатов кластеризации в отдельную колонку.
Эксперимент с алгоритмом классификации k ближайших соседей.
1.Обучение модели.
2.Сохранение модели в файл 'knn_model_tfidf.pkl'.
3.Сохранение scaler в файл 'scaler.pkl.
4.Расчет метрики roc-auc.
Файл Test_w2v:
1.Импорт библиотек.
2.Предсказание классов.
3.Вывод главных слов кластеров.
4.Проверка кластеров 61, 2, 4, 44, 58, 6.
Файл Test_tfidf:
1. Импорт библиотек.
2. Предсказание классов.
3. Вывод главных слова кластеров.
